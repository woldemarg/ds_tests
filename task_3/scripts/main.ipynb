{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "\n",
        "from sklearn.decomposition import PCA"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url = \"https://raw.githubusercontent.com/woldemarg/nix_solutions_test/master/task_3/data/Data%20for%20the%20Churn%20task%20_%20BDA%20homework.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "data.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.isnull().sum()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.nunique()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_mod = data.drop([\"customerID\",\n",
        "                      \"TotalCharges\"],\n",
        "                     axis=1)\n",
        "\n",
        "binary_cols = (data_mod.columns[(data_mod.nunique() == 2) &\n",
        "                                (data_mod.apply(\n",
        "                                    lambda s: all(s.str.contains(\"Yes|No\"))))]\n",
        "               .tolist())\n",
        "\n",
        "data_mod.loc[:, binary_cols] = (data_mod[binary_cols]\n",
        "                                .replace([\"Yes\", \"No\"], [1, 0]))\n",
        "\n",
        "threesome_cols = (data_mod.columns[(data_mod.nunique() == 3) &\n",
        "                                   (data_mod.apply(\n",
        "                                       lambda s:\n",
        "                                       all(s.str.contains(\"Yes|No\"))))]\n",
        "                  .tolist())\n",
        "\n",
        "data_mod.loc[:, threesome_cols] = (data_mod[threesome_cols]\n",
        "                                   .replace({\n",
        "                                       \"Yes\":1,\n",
        "                                       \"No\":0,\n",
        "                                       \"No phone service\":0,\n",
        "                                       \"No internet service\":0}))\n",
        "\n",
        "data_mod.loc[:, \"InternetService\"] = (data_mod.InternetService\n",
        "                                      .replace({\n",
        "                                          \"No\":0,\n",
        "                                          \"DSL\":1,\n",
        "                                          \"Fiber optic\":2}))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cat_cols_left = [col for col in data_mod\n",
        "                 if data_mod[col].dtype == \"object\"]\n",
        "\n",
        "OH_encoder = OneHotEncoder(handle_unknown=\"error\",\n",
        "                           drop=\"first\", sparse=False)\n",
        "\n",
        "OH_cols = pd.DataFrame(OH_encoder.fit_transform(data_mod[cat_cols_left]))\n",
        "\n",
        "OH_cols_names = OH_encoder.get_feature_names(cat_cols_left)\n",
        "OH_cols.columns = OH_cols_names\n",
        "\n",
        "data_num = pd.concat([data_mod.drop(cat_cols_left, axis=1), OH_cols],\n",
        "                     axis=1)\n",
        "\n",
        "data_num.head()\n",
        "# %%\n",
        "y = data_num.Churn\n",
        "X = data_num.drop([\"Churn\"], axis=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
        "X_scaled.columns = X.columns"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sl_scores = []\n",
        "ch_scores = []\n",
        "k_means_res = {}\n",
        "\n",
        "num_clusters = range(2, 11)\n",
        "\n",
        "for k in num_clusters:\n",
        "    k_means = KMeans(n_clusters=k).fit(X_scaled)\n",
        "\n",
        "    sl_scores.append(silhouette_score(X_scaled,\n",
        "                                      k_means.labels_,\n",
        "                                      metric = 'euclidean'))\n",
        "\n",
        "    ch_scores.append(calinski_harabasz_score(X_scaled,\n",
        "                                             k_means.labels_))\n",
        "\n",
        "    k_means_res.update({k: k_means.__dict__})"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = \"tab:red\"\n",
        "ax1.set_xlabel(\"num of clusters\")\n",
        "ax1.set_ylabel(\"CH scores\", color=color)\n",
        "ax1.plot(num_clusters, ch_scores, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.axvline(x=4, linestyle=\"--\", color=\"tab:grey\", linewidth=0.75)\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel(\"silhouette scores\", color=color)\n",
        "ax2.plot(num_clusters, sl_scores, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "af = AffinityPropagation().fit(X_scaled)\n",
        "cluster_centers = af.cluster_centers_indices_\n",
        "\n",
        "\n",
        "no_clusters = len(af.cluster_centers_indices_)\n",
        "k_best = 4"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca = PCA(n_components=2)\n",
        "\n",
        "principal_components = pca.fit_transform(X_scaled)\n",
        "\n",
        "principal_df = pd.DataFrame(data = principalComponents,\n",
        "                            columns = [\"PC_1\", \"PC_2\"])\n",
        "\n",
        "data_pca = pd.concat([principal_df,\n",
        "                      pd.Series(k_means_res[k_best][\"labels_\"],\n",
        "                                name=\"cluster_labels\"),\n",
        "                      y], axis=1)\n",
        "\n",
        "\n",
        "clusters = np.unique(data_pca.cluster_labels)\n",
        "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n",
        "colors_dict = dict(zip(clusters, colors))\n",
        "data_pca[\"cluster_colors\"] = (data_pca.cluster_labels\n",
        "                              .apply(lambda x: colors_dict[x]))\n",
        "\n",
        "\n",
        "data_pca.plot.scatter(x=\"PC_1\",\n",
        "                      y=\"PC_2\",\n",
        "                      c=data_pca.cluster_colors,\n",
        "                      s=3,\n",
        "                      alpha=0.5)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "churn_per_cluster = (data_pca\n",
        "                     .groupby([\"cluster_labels\", \"Churn\"])\n",
        "                     .agg({\"Churn\": \"count\"}))\n",
        "\n",
        "churn_per_cluster[\"ratio\"] = (churn_per_cluster\n",
        "                              .groupby(level=0)\n",
        "                              .apply(lambda x:\n",
        "                                     100 * x / x.sum()))\n",
        "\n",
        "\n",
        "cluster_size = data_pca.groupby(\"cluster_labels\").count()\n",
        "\n",
        "churn_ratio = (churn_per_cluster\n",
        "               .div(cluster_size, level=\"cluster_labels\")\n",
        "               .loc[:, \"Churn\"]\n",
        "               .rename(\"ratio\")\n",
        "               .reset_index()\n",
        "               .query(\"Churn == 1\"))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}