{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "from nlp.company_7.task_solution.scripts.keywords import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data.csv.gz\",\n",
    "                 index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>email</th>\n",
       "      <th>json</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>academic_title</th>\n",
       "      <th>department</th>\n",
       "      <th>school</th>\n",
       "      <th>processed</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.abac.edu/</td>\n",
       "      <td>vfenn@abac.edu</td>\n",
       "      <td>{\"left\": \" the winner. The number on each ball...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 11:37:24</td>\n",
       "      <td>2020-02-06 03:33:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.abac.edu/</td>\n",
       "      <td>bray@abac.edu</td>\n",
       "      <td>{\"left\": \"er person and can be purchased onlin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 11:37:24</td>\n",
       "      <td>2020-02-06 03:33:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.abac.edu/</td>\n",
       "      <td>admissions@abac.edu</td>\n",
       "      <td>{\"left\": \"ty, Prince Automotive Group, Rotary ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 11:37:24</td>\n",
       "      <td>2020-02-06 03:33:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.abac.edu/</td>\n",
       "      <td>webmaster@abac.edu</td>\n",
       "      <td>{\"left\": \"mics\\nRegistrar\\nTranscript Request\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 11:37:24</td>\n",
       "      <td>2020-02-06 03:33:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.alu.edu/</td>\n",
       "      <td>admissions@alu.edu</td>\n",
       "      <td>{\"left\": \"Abraham Lincoln University &amp; Online ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-16 11:37:24</td>\n",
       "      <td>2020-02-06 03:33:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url  ...           updated_at\n",
       "id                         ...                     \n",
       "1   https://www.abac.edu/  ...  2020-02-06 03:33:24\n",
       "2   https://www.abac.edu/  ...  2020-02-06 03:33:24\n",
       "3   https://www.abac.edu/  ...  2020-02-06 03:33:24\n",
       "4   https://www.abac.edu/  ...  2020-02-06 03:33:24\n",
       "5    https://www.alu.edu/  ...  2020-02-06 03:33:24\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_main = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\"])\n",
    "nlp_helper = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "\n",
    "for jsn in df[\"json\"]:\n",
    "    d = json.loads(jsn)\n",
    "    s = \"\".join(v.strip()\n",
    "                .replace(\"\\n\", \" \")\n",
    "                .replace(\"\\t\", \" \")\n",
    "                for v in d.values())\n",
    "    strings.append(s)\n",
    "\n",
    "s_strings = pd.Series(strings, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_all_propn(st):\n",
    "    propns = []\n",
    "    for w in st.split(\" \"):\n",
    "        w_doc = nlp_helper(w)\n",
    "        for t in w_doc:\n",
    "            propns.append(t.pos_)\n",
    "    return all((el == \"PROPN\" for el in propns))\n",
    "\n",
    "\n",
    "def correct_person_entities(nlp_doc):\n",
    "    new_ents = []\n",
    "    for ent in nlp_doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            if (re.search(r\"^([A-Z][\\w]+\\s[A-Z]?\\.?\\s?[A-Z][\\w]+)$\",\n",
    "                          ent.text) and is_all_propn(ent.text)):\n",
    "                new_ents.append(ent)\n",
    "        else:\n",
    "            new_ents.append(ent)\n",
    "    nlp_doc.ents = new_ents\n",
    "    return nlp_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "\n",
    "for k, v in keywords().items():\n",
    "    for s in v:\n",
    "        new = {}\n",
    "        new[\"label\"] = k\n",
    "        new[\"pattern\"] = [{\"LOWER\": w.lower()} for w in s.split(\" \")]\n",
    "        patterns.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = EntityRuler(nlp_main)\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_main.add_pipe(ruler, before=\"ner\")\n",
    "nlp_main.add_pipe(correct_person_entities, after=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ls = []\n",
    "\n",
    "for i, el in s_strings.items():\n",
    "    doc = nlp_main(el)\n",
    "    if (any([n.label_ == \"academic_title\" for n in doc.ents]) and\n",
    "            any([n.label_ == \"PERSON\" for n in doc.ents])):\n",
    "\n",
    "        names = [n.text for n in doc.ents if n.label_ == \"PERSON\"]\n",
    "        nx = np.asarray([n.start_char for n\n",
    "                         in doc.ents if n.label_ == \"PERSON\"])\n",
    "        titles = [n.text for n\n",
    "                  in doc.ents if n.label_ == \"academic_title\"]\n",
    "        ty = np.asarray([n.start_char for n\n",
    "                         in doc.ents if n.label_ == \"academic_title\"])\n",
    "\n",
    "        diff_arr = np.abs(ty - nx[:, np.newaxis])\n",
    "        min_vals = np.where(diff_arr == np.amin(diff_arr))\n",
    "        indicies = list(zip(min_vals[0], min_vals[1]))\n",
    "        data_ls.append((i, names[indicies[0][0]], titles[indicies[0][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_ls, columns=[\"id\", \"name\", \"academic_title\"])\n",
    "data_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "\n",
    "def remove_middle_name(nn):\n",
    "    n = nn.split(\" \")\n",
    "    return \" \".join((n[0], n[-1]))\n",
    "\n",
    "\n",
    "data_df.loc[:, \"name\"] = data_df[\"name\"].map(remove_middle_name)\n",
    "data_df[[\"first_name\", \"last_name\"]] = data_df[\"name\"].str.split(expand=True)\n",
    "\n",
    "data_df.loc[:, \"academic_title\"] = data_df[\"academic_title\"].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(data_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 - df[\"first_name\"].isna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.to_csv(\"../results/data_new.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 ms ± 13.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def get_data(line):\n",
    "    l_doc = nlp_main(line)\n",
    "    if (any([n.label_ == \"academic_title\" for n in l_doc.ents]) and\n",
    "            any([n.label_ == \"PERSON\" for n in l_doc.ents])):\n",
    "\n",
    "        names = [n.text for n in l_doc.ents if n.label_ == \"PERSON\"]\n",
    "        nx = np.asarray([n.start_char for n\n",
    "                         in l_doc.ents if n.label_ == \"PERSON\"])\n",
    "        titles = [n.text for n\n",
    "                  in l_doc.ents if n.label_ == \"academic_title\"]\n",
    "        ty = np.asarray([n.start_char for n\n",
    "                         in l_doc.ents if n.label_ == \"academic_title\"])\n",
    "\n",
    "        diff_arr = np.abs(ty - nx[:, np.newaxis])\n",
    "        min_vals = np.where(diff_arr == np.amin(diff_arr))\n",
    "        indicies = list(zip(min_vals[0], min_vals[1]))\n",
    "        return (names[indicies[0][0]], titles[indicies[0][1]])\n",
    "\n",
    "\n",
    "%timeit get_data(s_strings[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
